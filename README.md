# ğŸ›¡ï¸ SpamShield - Projet SMS Spam Detection

## ğŸ¯ AperÃ§u du projet

**SpamShield** est un systÃ¨me de dÃ©tection de spam SMS utilisant trois approches d'apprentissage automatique diffÃ©rentes pour comparer leurs performances et efficacitÃ©.

### Objectifs
- âœ… ImplÃ©menter et comparer 3 approches de classification de texte
- âœ… CrÃ©er une interface utilisateur interactive avec Gradio
- âœ… DÃ©ployer le systÃ¨me pour une utilisation publique
- âœ… Analyser les performances de chaque approche

### Technologies utilisÃ©es
- **Framework ML** : Transformers (Hugging Face)
- **Interface** : Gradio
- **ModÃ¨les** : BART-MNLI, DistilBERT, DialoGPT
- **Dataset** : SMS Spam Collection
- **DÃ©ploiement** : Local + Hugging Face Spaces

## ğŸ—ï¸ Architecture technique

### 1. ğŸ¯ Zero-Shot Classification
```python
ModÃ¨le: facebook/bart-large-mnli
Principe: Classification sans entraÃ®nement spÃ©cifique
Labels: ["legitimate message", "spam message"]
```

### 2. ğŸ“ Few-Shot Learning
```python
Approche: Analyse heuristique avec mots-clÃ©s
Signaux dÃ©tectÃ©s:
- Mots-clÃ©s spam: free, win, prize, urgent, etc.
- Indicateurs: Â£, $, %, majuscules, longueur
```

### 3. ğŸ‹ï¸ Fine-Tuning
```python
ModÃ¨le de base: distilbert-base-uncased
Dataset: SMS Spam Ã©quilibrÃ© (747 ham + 747 spam)
EntraÃ®nement: 10 Ã©poques, batch_size=8
```

## ğŸ“Š RÃ©sultats obtenus

### Performances finales
| ModÃ¨le | Accuracy | PrÃ©cision | Rappel | F1-Score |
|--------|----------|-----------|---------|----------|
| **Few-Shot** | **67.2%** | 80% | 67% | 63% |
| **Zero-Shot** | 52.0% | N/A | N/A | N/A |
| **Fine-Tuned** | 50.2% | 25% | 50% | 34% |

### ğŸ† Classement des modÃ¨les
1. **ğŸ¥‡ Few-Shot Learning** - Meilleur Ã©quilibre performance/simplicitÃ©
2. **ğŸ¥ˆ Zero-Shot Classification** - Performance correcte sans entraÃ®nement
3. **ğŸ¥‰ Fine-Tuned Model** - ProblÃ¨mes de mapping et overfitting

## âŒ ProblÃ¨mes rencontrÃ©s

### 1. **ProblÃ¨me de dÃ©pendances**
```bash
TypeError: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'
```
**Cause** : Changement de nom du paramÃ¨tre dans Transformers  
**Solution** : `evaluation_strategy` â†’ `eval_strategy`

### 2. **Dataset dÃ©sÃ©quilibrÃ©**
```
Ham: 4827 messages (86.6%)
Spam: 747 messages (13.4%)
```
**Impact** : Biais vers la classe majoritaire  
**Solution** : Sous-Ã©chantillonnage pour Ã©quilibrer

### 3. **Mauvaises performances du Fine-Tuned**
```
Fine-Tuned Accuracy: 50.2% (attendu: >90%)
Warning: Precision ill-defined for labels with no predicted samples
```
**Causes identifiÃ©es** :
- Mapping incorrect des labels (`LABEL_0`/`LABEL_1`)
- Overfitting (97% train â†’ 50% test)
- Dataset trop petit aprÃ¨s Ã©quilibrage

## âœ… Solutions implÃ©mentÃ©es

### 1. **Correction des dÃ©pendances**
```python
# Avant
evaluation_strategy="epoch"
# AprÃ¨s
eval_strategy="epoch"
```

### 2. **Ã‰quilibrage du dataset**
```python
# Sous-Ã©chantillonnage de la classe majoritaire
min_samples = min(len(df_ham), len(df_spam))
df_balanced = pd.concat([df_ham.sample(min_samples), df_spam.sample(min_samples)])
```

### 3. **AmÃ©lioration du Fine-Tuned**
```python
# Mapping des labels corrigÃ©
if '0' in label or 'LABEL_0' in label:
    prediction = "Ham (LÃ©gitime)"
elif '1' in label or 'LABEL_1' in label:
    prediction = "Spam"
```

## ğŸ”§ Points d'amÃ©lioration

### ğŸš€ AmÃ©lioration immÃ©diate (facile)

#### Dataset
- **Augmenter la taille** : Utiliser plus de donnÃ©es d'entraÃ®nement
- **Validation croisÃ©e** : K-fold pour une Ã©valuation robuste
- **Stratification** : Maintenir la distribution lors des splits

#### Fine-Tuning
```python
# ParamÃ¨tres suggÃ©rÃ©s
training_args = TrainingArguments(
    num_train_epochs=5,  # RÃ©duire pour Ã©viter l'overfitting
    learning_rate=1e-5,  # Learning rate plus faible
    early_stopping_patience=3,  # Early stopping
    warmup_ratio=0.1,
)
```

#### Few-Shot
```python
# AmÃ©liorer les mots-clÃ©s
spam_keywords += ['exclusive', 'limited', 'act now', 'expires', 'credit']
# Ajouter un scoring pondÃ©rÃ©
weights = {'free': 2, 'win': 2, 'urgent': 3}
```

### ğŸ¯ AmÃ©lioration avancÃ©e (moyen terme)

#### Nouveaux modÃ¨les
- **RoBERTa** au lieu de DistilBERT
- **Ensemble methods** : Combiner les prÃ©dictions
- **BERT spÃ©cialisÃ©** pour les SMS courts

#### Techniques avancÃ©es
```python
# Data augmentation
from nlpaug import AugmentationPipeline
# Feature engineering
from sklearn.feature_extraction.text import TfidfVectorizer
# Hyperparameter tuning
from optuna import create_study
```

#### MÃ©triques avancÃ©es
- **ROC-AUC** : Courbe ROC pour Ã©valuer la discrimination
- **Confusion Matrix** : Analyse dÃ©taillÃ©e des erreurs
- **Cross-validation** : Validation plus robuste

### ğŸŒŸ AmÃ©lioration Ã  long terme

#### Architecture
- **API REST** : DÃ©ploiement scalable
- **Base de donnÃ©es** : Stockage des prÃ©dictions
- **Monitoring** : Suivi des performances en production

#### Interface
- **Dashboard analytics** : Statistiques dÃ©taillÃ©es
- **Feedback utilisateur** : AmÃ©lioration continue
- **Historique** : Sauvegarde des analyses

## ğŸ“¥ Installation et utilisation

### PrÃ©requis
```bash
Python 3.8+
CUDA (optionnel, pour GPU)
4GB RAM minimum, 8GB recommandÃ©
```

### Installation
```bash
# Cloner le projet
git clone <votre-repo>
cd spamshield

# Environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate    # Windows

# DÃ©pendances
pip install -r requirements.txt
```

### Utilisation
```bash
# 1. EntraÃ®ner les modÃ¨les
python train_models.py

# 2. Lancer l'interface
python app.py

# 3. Ouvrir http://127.0.0.1:7860
```

### Structure du projet
```
spamshield/
â”œâ”€â”€ train_models.py       # EntraÃ®nement des 3 modÃ¨les
â”œâ”€â”€ app.py               # Interface Gradio
â”œâ”€â”€ requirements.txt     # DÃ©pendances
â”œâ”€â”€ README.md           # Ce fichier
â”œâ”€â”€ models/             # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ fine_tuned_model/
â”‚   â”œâ”€â”€ model_info.pkl
```

## ğŸ¯ RÃ©sultats d'apprentissage

### âœ… Objectifs atteints
- [x] ImplÃ©mentation de 3 approches ML diffÃ©rentes
- [x] Interface utilisateur fonctionnelle
- [x] Comparaison des performances
- [x] DÃ©ploiement local rÃ©ussi
- [x] Documentation complÃ¨te

### ğŸ“š CompÃ©tences dÃ©veloppÃ©es
- **Transformers** : Utilisation de modÃ¨les prÃ©-entraÃ®nÃ©s
- **Gradio** : CrÃ©ation d'interfaces ML
- **Classification de texte** : Preprocessing et Ã©valuation
- **Debugging** : RÃ©solution de problÃ¨mes techniques
- **Documentation** : Rapport technique dÃ©taillÃ©

### ğŸ” LeÃ§ons apprises
1. **L'Ã©quilibrage des donnÃ©es** est crucial pour Ã©viter les biais
2. **Le fine-tuning** n'est pas toujours la meilleure solution
3. **Les approches simples** (Few-Shot) peuvent Ãªtre trÃ¨s efficaces
4. **Le debugging** est une partie importante du dÃ©veloppement ML
5. **La documentation** aide Ã  identifier et rÃ©soudre les problÃ¨mes

## ğŸ“ˆ MÃ©triques dÃ©taillÃ©es

### Few-Shot (Meilleur modÃ¨le)
```
              precision    recall  f1-score   support
         Ham       0.60      1.00      0.75       150
        Spam       1.00      0.34      0.51       149
    accuracy                           0.67       299
```

**Analyse** :
- âœ… **TrÃ¨s bonne prÃ©cision** pour dÃ©tecter le spam (100%)
- âŒ **Faible rappel** pour le spam (34% seulement dÃ©tectÃ©s)
- ğŸ¯ **Ã‰quilibrÃ©** entre les deux classes

### Zero-Shot
```
Accuracy: 52% (sur Ã©chantillon limitÃ©)
```

**Analyse** :
- âœ… **Aucun entraÃ®nement** requis
- âŒ **Performance limitÃ©e** sur domaine spÃ©cialisÃ©
- ğŸ¯ **Bonne baseline** pour comparaison

### Fine-Tuned (ProblÃ©matique)
```
              precision    recall  f1-score   support
         Ham       0.50      1.00      0.67       150
        Spam       0.00      0.00      0.00       149
```

**Analyse** :
- âŒ **Aucun spam dÃ©tectÃ©** (rappel = 0%)
- âŒ **Overfitting sÃ©vÃ¨re** (97% train â†’ 50% test)
- ğŸ”§ **NÃ©cessite refactoring** du mapping des labels

## ğŸš€ DÃ©ploiement

### Local âœ…
```bash
python app.py
# â†’ http://127.0.0.1:7860
```

### Hugging Face Spaces (optionnel)
```bash
# CrÃ©er un Space sur huggingface.co
# Uploader les fichiers
git push origin main
# â†’ https://huggingface.co/spaces/username/spamshield
```

## ğŸ‰ Conclusion

### Bilan du projet
**SpamShield** dÃ©montre avec succÃ¨s l'implÃ©mentation et la comparaison de trois approches de classification de texte. MalgrÃ© les dÃ©fis techniques rencontrÃ©s, le projet atteint ses objectifs principaux et fournit des insights prÃ©cieux sur les diffÃ©rentes mÃ©thodes ML.

### Points forts
- âœ… **Architecture modulaire** facilitant les amÃ©liorations
- âœ… **Interface utilisateur** intuitive et fonctionnelle  
- âœ… **Comparaison rigoureuse** des approches
- âœ… **Documentation complÃ¨te** des problÃ¨mes et solutions
- âœ… **Code reproductible** avec gestion d'erreurs

### Impact pÃ©dagogique
Ce projet illustre parfaitement les rÃ©alitÃ©s du dÃ©veloppement ML :
- Les **dÃ©fis techniques** inattendus
- L'importance du **preprocessing** des donnÃ©es
- La **complexitÃ©** du fine-tuning vs approches simples
- La valeur de la **documentation** et du debugging

### Perspectives d'Ã©volution
SpamShield constitue une **base solide** pour des amÃ©liorations futures et peut servir de **template** pour d'autres projets de classification de texte.

---

**DÃ©veloppÃ© avec â¤ï¸ pour l'apprentissage de la classification de texte**

*Projet rÃ©alisÃ© dans le cadre d'un cours de Text Classification - Novembre 2024*