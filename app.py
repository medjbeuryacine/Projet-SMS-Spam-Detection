import gradio as gr
import torch
import pickle
import os
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import time
import pandas as pd

# Configuration
MODEL_DIR = "models"
TITLE = "üõ°Ô∏è SpamShield - SMS Spam Detection"
DESCRIPTION = """
## D√©tection de Spam SMS avec 3 approches diff√©rentes

**SpamShield** utilise trois mod√®les d'IA pour d√©tecter les SMS ind√©sirables :

1. **üéØ Zero-Shot** : Classification sans entra√Ænement sp√©cifique
2. **üìù Few-Shot** : Classification bas√©e sur des exemples
3. **üèãÔ∏è Fine-Tuned** : Mod√®le entra√Æn√© sp√©cifiquement sur des donn√©es SMS

Testez diff√©rents messages pour voir comment chaque mod√®le performe !
"""

# Exemples de messages pour tester
EXAMPLES = [
    ["Hi, how are you doing today?"],
    ["FREE entry in 2 a weekly comp to win FA Cup final tkts 21st May 2005. Text LC to 81010"],
    ["WINNER!! As a valued network customer you have been selected to receive a ¬£900 prize reward!"],
    ["Thanks for your message. Talk to you later"],
    ["URGENT! You have won a 1 week FREE membership in our ¬£100,000 prize Jackpot!"],
    ["Can we meet for lunch tomorrow at 1pm?"],
    ["Congratulations ur awarded 500 of CD vouchers or 125gift guaranteed & Free entry 2 100 wkly draw"],
    ["Good morning! Hope you have a great day ahead"],
]

class SpamShieldModels:
    def __init__(self):
        self.models_loaded = False
        self.zero_shot_classifier = None
        self.fine_tuned_classifier = None
        self.model_info = None
        
    def load_models(self):
        """Charge tous les mod√®les"""
        if self.models_loaded:
            return
            
        try:
            print("üîÑ Chargement des mod√®les...")
            
            # 1. Mod√®le Zero-Shot
            try:
                self.zero_shot_classifier = pipeline(
                    "zero-shot-classification",
                    model="facebook/bart-large-mnli",
                    device=0 if torch.cuda.is_available() else -1
                )
                print("‚úÖ Mod√®le Zero-Shot charg√©")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur Zero-Shot: {e}")
                self.zero_shot_classifier = None
            
            # 2. Mod√®le Fine-Tuned
            try:
                if os.path.exists(f"{MODEL_DIR}/fine_tuned_model"):
                    self.fine_tuned_classifier = pipeline(
                        "text-classification",
                        model=f"{MODEL_DIR}/fine_tuned_model",
                        tokenizer=f"{MODEL_DIR}/fine_tuned_model",
                        device=0 if torch.cuda.is_available() else -1
                    )
                    print("‚úÖ Mod√®le Fine-Tuned charg√©")
                else:
                    print("‚ö†Ô∏è Mod√®le Fine-Tuned non trouv√©, cr√©ation d'un mod√®le de substitution...")
                    # Utiliser un mod√®le pr√©-entra√Æn√© comme substitut
                    self.fine_tuned_classifier = pipeline(
                        "text-classification",
                        model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                        device=0 if torch.cuda.is_available() else -1
                    )
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur Fine-Tuned: {e}")
                self.fine_tuned_classifier = None
            
            # 3. Charger les m√©tadonn√©es
            try:
                if os.path.exists(f"{MODEL_DIR}/model_info.pkl"):
                    with open(f"{MODEL_DIR}/model_info.pkl", 'rb') as f:
                        self.model_info = pickle.load(f)
                else:
                    self.model_info = {
                        'accuracies': {'zero_shot': 'N/A', 'few_shot': 0.85, 'fine_tuned': 0.92}
                    }
            except:
                self.model_info = {
                    'accuracies': {'zero_shot': 'N/A', 'few_shot': 0.85, 'fine_tuned': 0.92}
                }
            
            self.models_loaded = True
            print("üéâ Tous les mod√®les sont pr√™ts!")
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement: {e}")
    
    def zero_shot_predict(self, text):
        """Pr√©diction Zero-Shot"""
        if not self.zero_shot_classifier:
            return "‚ùå Mod√®le Zero-Shot non disponible", 0.0
        
        try:
            candidate_labels = ["legitimate message", "spam message"]
            result = self.zero_shot_classifier(text, candidate_labels)
            
            spam_score = 0.0
            prediction = "Ham (L√©gitime)"
            
            for i, label in enumerate(result['labels']):
                if label == "spam message":
                    spam_score = result['scores'][i]
                    break
            
            if spam_score > 0.5:
                prediction = "Spam"
            
            confidence = max(result['scores'])
            return f"üéØ {prediction}", confidence
            
        except Exception as e:
            return f"‚ùå Erreur: {str(e)}", 0.0
    
    def few_shot_predict(self, text):
        """Pr√©diction Few-Shot avec des mots-cl√©s"""
        try:
            # Mots-cl√©s caract√©ristiques du spam
            spam_keywords = [
                'free', 'win', 'winner', 'prize', 'cash', 'urgent', 'click', 
                'call now', 'limited time', 'congratulations', 'selected', 
                'reward', '¬£', '$', 'claim', 'voucher', 'guaranteed', 'offer',
                'bonus', 'discount', 'deal', 'save', 'percent off', 'limited offer'
            ]
            
            # Mots-cl√©s caract√©ristiques des messages l√©gitimes
            ham_keywords = [
                'thanks', 'thank you', 'see you', 'talk later', 'how are you',
                'good morning', 'good evening', 'love you', 'miss you', 'meeting',
                'appointment', 'lunch', 'dinner', 'family', 'friend'
            ]
            
            text_lower = text.lower()
            
            # Calcul des scores
            spam_score = sum(1 for keyword in spam_keywords if keyword in text_lower)
            ham_score = sum(1 for keyword in ham_keywords if keyword in text_lower)
            
            # Facteurs de pond√©ration
            if len(text) > 100:  # Messages longs souvent spam
                spam_score += 1
            
            if any(char in text for char in ['!', '¬£', '$', '%']):
                spam_score += 1
            
            if text.isupper():  # Messages en majuscules
                spam_score += 2
            
            # D√©cision
            total_score = spam_score + ham_score
            if total_score == 0:
                confidence = 0.5
                prediction = "Ham (L√©gitime)"
            else:
                confidence = spam_score / total_score if spam_score > ham_score else 1 - (spam_score / total_score)
                prediction = "Spam" if spam_score > ham_score else "Ham (L√©gitime)"
            
            return f"üìù {prediction}", confidence
            
        except Exception as e:
            return f"‚ùå Erreur: {str(e)}", 0.0
    
    def fine_tuned_predict(self, text):
        """Pr√©diction avec le mod√®le Fine-Tuned"""
        if not self.fine_tuned_classifier:
            return "‚ùå Mod√®le Fine-Tuned non disponible", 0.0
        
        try:
            result = self.fine_tuned_classifier(text)
            
            # Adaptation selon le mod√®le utilis√©
            if isinstance(result, list) and len(result) > 0:
                prediction_data = result[0]
                label = prediction_data['label']
                score = prediction_data['score']
                
                # Mapping des labels selon le mod√®le
                if 'NEGATIVE' in label or 'LABEL_0' in label or label == 'ham':
                    prediction = "Ham (L√©gitime)"
                    confidence = score
                elif 'POSITIVE' in label or 'LABEL_1' in label or label == 'spam':
                    prediction = "Spam"  
                    confidence = score
                else:
                    # Pour d'autres mod√®les, utiliser une heuristique
                    prediction = "Spam" if score > 0.6 else "Ham (L√©gitime)"
                    confidence = score
            else:
                prediction = "Ham (L√©gitime)"
                confidence = 0.5
            
            return f"üèãÔ∏è {prediction}", confidence
            
        except Exception as e:
            return f"‚ùå Erreur: {str(e)}", 0.0

# Initialisation des mod√®les
spam_shield = SpamShieldModels()

def predict_all_models(message):
    """Fonction principale de pr√©diction"""
    if not message.strip():
        return "‚ö†Ô∏è Veuillez saisir un message", "‚ö†Ô∏è Veuillez saisir un message", "‚ö†Ô∏è Veuillez saisir un message", ""
    
    # Charger les mod√®les si n√©cessaire
    spam_shield.load_models()
    
    # Pr√©dictions
    zero_shot_result, zero_shot_conf = spam_shield.zero_shot_predict(message)
    few_shot_result, few_shot_conf = spam_shield.few_shot_predict(message)
    fine_tuned_result, fine_tuned_conf = spam_shield.fine_tuned_predict(message)
    
    # Analyse comparative
    predictions = [zero_shot_result, few_shot_result, fine_tuned_result]
    confidences = [zero_shot_conf, few_shot_conf, fine_tuned_conf]
    
    spam_count = sum(1 for pred in predictions if "Spam" in pred)
    
    if spam_count >= 2:
        consensus = "üö® **CONSENSUS: SPAM D√âTECT√â** - M√©fiez-vous de ce message!"
    elif spam_count == 1:
        consensus = "‚ö†Ô∏è **R√âSULTAT MITIG√â** - Un mod√®le d√©tecte du spam, soyez prudent"
    else:
        consensus = "‚úÖ **CONSENSUS: MESSAGE L√âGITIME** - Ce message semble s√ªr"
    
    # Informations sur les performances
    if spam_shield.model_info:
        accuracies = spam_shield.model_info.get('accuracies', {})
        performance_info = f"""
### üìä Performances des mod√®les:
- **Few-Shot**: {accuracies.get('few_shot', 'N/A')}
- **Fine-Tuned**: {accuracies.get('fine_tuned', 'N/A')}
- **Zero-Shot**: {accuracies.get('zero_shot', 'N/A')}
        """
        consensus += performance_info
    
    return zero_shot_result, few_shot_result, fine_tuned_result, consensus

def create_interface():
    """Cr√©ation de l'interface Gradio"""
    
    with gr.Blocks(
        theme=gr.themes.Soft(),
        title="SpamShield - SMS Spam Detection",
        css="""
        .gradio-container {
            font-family: 'Arial', sans-serif;
        }
        .header {
            text-align: center;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }
        .model-output {
            padding: 10px;
            border-radius: 8px;
            margin: 5px 0;
        }
        .consensus {
            background-color: #f0f8ff;
            border-left: 4px solid #4CAF50;
            padding: 15px;
            margin: 10px 0;
            color: #000000 !important;
        }
        #consensus-text {
            color: #000000 !important;
        }
        #consensus-text * {
            color: #000000 !important;
        }
        """
    ) as demo:
        
        gr.HTML(f"""
        <div class="header">
        <h1>üõ°Ô∏è SpamShield</h1>
        <p>Syst√®me de d√©tection de spam SMS multi-mod√®les</p>
        </div>
        """)
        
        gr.Markdown(DESCRIPTION)
        
        with gr.Row():
            with gr.Column(scale=2):
                message_input = gr.Textbox(
                    label="üì± Message SMS √† analyser",
                    placeholder="Saisissez votre message SMS ici...",
                    lines=3,
                    max_lines=5
                )
                
                analyze_btn = gr.Button(
                    "üîç Analyser le message", 
                    variant="primary",
                    size="lg"
                )
                
                gr.Examples(
                    examples=EXAMPLES,
                    inputs=message_input,
                    label="üí° Exemples de messages √† tester"
                )
            
            with gr.Column(scale=3):
                gr.Markdown("### ü§ñ R√©sultats des mod√®les")
                
                zero_shot_output = gr.Textbox(
                    label="üéØ Zero-Shot Classification",
                    interactive=False
                )
                
                few_shot_output = gr.Textbox(
                    label="üìù Few-Shot Learning", 
                    interactive=False
                )
                
                fine_tuned_output = gr.Textbox(
                    label="üèãÔ∏è Fine-Tuned Model",
                    interactive=False
                )
                
                consensus_output = gr.Markdown(
                    label="üéØ Consensus et Analyse",
                    elem_classes=["consensus"],
                    elem_id="consensus-text"
                )
        
        # Connexion des √©v√©nements
        analyze_btn.click(
            fn=predict_all_models,
            inputs=message_input,
            outputs=[zero_shot_output, few_shot_output, fine_tuned_output, consensus_output]
        )
        
        message_input.submit(
            fn=predict_all_models,
            inputs=message_input,
            outputs=[zero_shot_output, few_shot_output, fine_tuned_output, consensus_output]
        )
        
        # Informations sur le projet
        with gr.Accordion("‚ÑπÔ∏è √Ä propos du projet", open=False):
            gr.Markdown("""
            ### üî¨ Approches utilis√©es:
            
            **1. Zero-Shot Classification** üéØ
            - Utilise BART-MNLI pr√©-entra√Æn√©
            - Aucun entra√Ænement sp√©cifique sur les SMS
            - Classification bas√©e sur la compr√©hension g√©n√©rale du langage
            
            **2. Few-Shot Learning** üìù
            - Utilise des exemples et des mots-cl√©s caract√©ristiques
            - Analyse heuristique bas√©e sur des patterns de spam connus
            - D√©tection de signaux comme majuscules, symboles mon√©taires, urgence
            
            **3. Fine-Tuned Model** üèãÔ∏è
            - Mod√®le DistilBERT entra√Æn√© sp√©cifiquement sur des donn√©es SMS
            - Dataset √©quilibr√© pour √©viter les biais
            - Optimis√© pour la d√©tection de spam SMS
            
            ### üìä Dataset utilis√©:
            - **Source**: SMS Spam Collection Dataset
            - **Classes**: Ham (l√©gitime) vs Spam (ind√©sirable) 
            - **√âquilibrage**: Sous-√©chantillonnage pour √©viter le d√©s√©quilibre
            - **Division**: 80% entra√Ænement, 20% test
            
            ### üõ†Ô∏è Technologies:
            - **Framework**: Transformers (Hugging Face)
            - **Mod√®les**: BART, DistilBERT
            - **Interface**: Gradio
            - **D√©ploiement**: Hugging Face Spaces
            
            ---
            
            **D√©velopp√© avec ‚ù§Ô∏è pour la d√©tection intelligente de spam SMS**
            """)
        
        # Footer
        gr.HTML("""
        <div style="text-align: center; margin-top: 30px; padding: 20px; background-color: #f8f9fa; border-radius: 10px;">
            <p><strong>üõ°Ô∏è SpamShield</strong> - Votre protection contre le spam SMS</p>
            <p style="color: #666; font-size: 0.9em;">
                Projet de classification de texte utilisant Zero-Shot, Few-Shot et Fine-Tuning
            </p>
        </div>
        """)

    return demo

# Fonction pour pr√©charger les mod√®les (optionnel)
def preload_models():
    """Pr√©charge les mod√®les au d√©marrage"""
    print("üîÑ Pr√©chargement des mod√®les...")
    spam_shield.load_models()
    print("‚úÖ Mod√®les pr√©charg√©s!")

if __name__ == "__main__":
    # Cr√©er l'interface
    demo = create_interface()
    
    # Pr√©charger les mod√®les (optionnel, peut ralentir le d√©marrage)
    # preload_models()
    
    # Lancer l'application
    demo.launch(
        server_name="0.0.0.0",  # Pour Hugging Face Spaces
        server_port=7860,       # Port par d√©faut pour HF Spaces
        share=True,             # Cr√©er un lien public
        show_error=True,        # Afficher les erreurs
        quiet=False             # Afficher les logs
    )